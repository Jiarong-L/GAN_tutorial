{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccb3a0df-0326-4774-9e20-cfb6de535528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0 device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "device = (\n",
    "    \"cuda:0\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b878782-dae7-4309-9e2a-b51e7eee4bee",
   "metadata": {},
   "source": [
    "## LoadData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39cd6ef5-ff5b-48b5-9179-285ca5235721",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext \n",
    "\n",
    "train_data = list(torchtext.datasets.IMDB(split='train',root=r'L:\\Datasets'))[12500:12600]\n",
    "tokenizer = torchtext.data.utils.get_tokenizer('basic_english')\n",
    "def yield_tokens(data):\n",
    "    for (_,text) in data:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "vocab = torchtext.vocab.build_vocab_from_iterator(yield_tokens(train_data),specials=['<unk>','<sos>','<eos>'],min_freq=3) ## '<pad>',\n",
    "vocab.set_default_index(vocab['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28eaeeb4-2d40-4ce2-aa61-bb2ee60ecb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch_noLable(data_batch):\n",
    "    text_lst = []\n",
    "    for _, _text in data_batch:\n",
    "        tk_text = vocab(['<sos>'] + tokenizer(_text) + ['<eos>'])\n",
    "        text_lst.append(torch.tensor(tk_text,dtype=torch.int64))\n",
    "    text_lst = torch.nn.utils.rnn.pad_sequence(text_lst, padding_value=float(vocab['<eos>']) )  ## pad 0 to equal length\n",
    "    return text_lst.to(device)\n",
    "\n",
    "test_dl_noLable = torch.utils.data.DataLoader(train_data, batch_size=20, shuffle=True, collate_fn = collate_batch_noLable) \n",
    "## [seq_len, batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4551ea43-be67-49fa-94f6-482a799851c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc30767f-7aa2-424e-a407-932fb9cc9370",
   "metadata": {},
   "source": [
    "## Pre-train Embedder\n",
    "主要是为了后续 Retrieve from Embedding Vector；此处只是个玩具，建议使用pre-train的word2vec等模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ccfaade-7300-4155-b92e-2dd0840507d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Emb2Class(\n",
       "  (emb): Embedding(1110, 300)\n",
       "  (fc): Linear(in_features=300, out_features=1110, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Emb2Class(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.fc = nn.Linear(embed_dim, vocab_size)\n",
    "    def forward(self,inputs):\n",
    "        emb = self.emb(inputs)\n",
    "        return self.fc(emb)#.argmax(dim=2)\n",
    "\n",
    "embed_dim = 300\n",
    "vocab_size = len(vocab)\n",
    "Emb2Class_model = Emb2Class(vocab_size, embed_dim).to(device)\n",
    "Emb2Class_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ec1eb8a-44be-4b36-9c5b-ace7631e8449",
   "metadata": {},
   "outputs": [],
   "source": [
    "ce = nn.CrossEntropyLoss()\n",
    "def Emb2Class_lossfn(pred,real):\n",
    "    loss = 0\n",
    "    for i in range(real.shape[0]):\n",
    "        loss += ce(pred[i],real[i])\n",
    "    return loss/real.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ed51f6b-d69c-44e8-ae61-a6d004818c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Emb2Class_optimizer = torch.optim.SGD(Emb2Class_model.parameters(), lr=1e-3)\n",
    "\n",
    "def Emb2Class_train(dataloader, model, loss_fn, optimizer):\n",
    "    lossSum = 0\n",
    "    model.train()                              ### set training mode\n",
    "    for inputs in dataloader:\n",
    "        pred = model(inputs)\n",
    "        loss = loss_fn(pred,inputs)\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        print(\"=\".format(epoch+1),end='')\n",
    "    print(\"last batch loss:{}\".format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b27fec7a-0a60-4582-95bf-548b3fff66b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1\t=====last batch loss:6.195950508117676\n",
      "Epoch:2\t=====last batch loss:5.4163336753845215\n",
      "Epoch:3\t=====last batch loss:5.043501853942871\n",
      "Epoch:4\t=====last batch loss:4.313214302062988\n",
      "Epoch:5\t=====last batch loss:3.695521593093872\n",
      "Epoch:6\t=====last batch loss:3.0953471660614014\n",
      "Epoch:7\t=====last batch loss:2.9020485877990723\n",
      "Epoch:8\t=====last batch loss:3.0827300548553467\n",
      "Epoch:9\t=====last batch loss:3.065711736679077\n",
      "Epoch:10\t=====last batch loss:2.2469937801361084\n",
      "Epoch:11\t=====last batch loss:2.782947540283203\n",
      "Epoch:12\t=====last batch loss:2.455803632736206\n",
      "Epoch:13\t=====last batch loss:3.3548364639282227\n",
      "Epoch:14\t=====last batch loss:2.3363473415374756\n",
      "Epoch:15\t=====last batch loss:2.288115978240967\n",
      "Epoch:16\t=====last batch loss:3.062293529510498\n",
      "Epoch:17\t=====last batch loss:2.3599071502685547\n",
      "Epoch:18\t=====last batch loss:2.2705986499786377\n",
      "Epoch:19\t=====last batch loss:2.7228190898895264\n",
      "Epoch:20\t=====last batch loss:2.1954903602600098\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    print(\"Epoch:{}\".format(epoch+1),end='\\t')\n",
    "    Emb2Class_train(test_dl_noLable, Emb2Class_model, Emb2Class_lossfn, Emb2Class_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "916d1218-fe49-4930-8b3b-a94bf9e6f87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_param_emb = Emb2Class_model.emb.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbf63fc-ede1-4fcd-bdfc-8cd677729902",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "057c2837-4715-4884-96a7-ce497a6c45d7",
   "metadata": {},
   "source": [
    "## RNN Encoder-Decoder\n",
    "\n",
    "```\n",
    "Encoder:\n",
    "ht_0 --> RNN_Cell --> ht_1 --> RNN_Cell --> ht_2 --> RNN_Cell --> .... --> RNN_Cell --> ht_end\n",
    "             ^                    ^                      ^                    ^\n",
    "         word1_batch             word2                  word3                word_end\n",
    "\n",
    "\n",
    "Decoder:\n",
    "ht_0 --> RNN_Cell --> ht_1 --> RNN_Cell --> ht_2 --> RNN_Cell --> .... --> RNN_Cell --> ht_stop <eos>\n",
    "          ^            |       ^              |       ^\n",
    "<SOS>   __|            o_1   __|              o_2   __|       也可以每步将 ht_0 + o_t or [o_1,...o_t] 作为输入\n",
    "\n",
    "\n",
    "GRU/Transformer 同理类似\n",
    "```\n",
    "\n",
    "### 参考\n",
    "https://zhuanlan.zhihu.com/p/80866196\n",
    "\n",
    "LSTM: https://curow.github.io/blog/LSTM-Encoder-Decoder/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "225f3236-7cc3-4c64-b794-3231010ede8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tt = nn.RNNCell(8,6)\n",
    "# tt( torch.zeros((1,8)) ,torch.zeros((1,6)) ).shape   ##==>torch.Size([1, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7d74ee0-a984-4f26-a0a2-98ea3245c49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_encoder(nn.Module):\n",
    "    def __init__(self, embed_dim, hidden_unitE):\n",
    "        super().__init__()\n",
    "        self.rnn_cell = nn.RNNCell(embed_dim,hidden_unitE)\n",
    "        self.hidden_unitE = hidden_unitE\n",
    "    def forward(self,inputs):\n",
    "        htE = torch.zeros((inputs.shape[1],self.hidden_unitE)).to(device)  ## (batch_size,hidden_unitE)\n",
    "        for word in inputs:\n",
    "            # if len(torch.nonzero(word-vocab['eos']))== 0:      ## when all words == vocab['eos']\n",
    "            #     break\n",
    "            htE = self.rnn_cell(word,htE)\n",
    "        return htE\n",
    "\n",
    "class RNN_decoder(nn.Module):\n",
    "    def __init__(self, embed_dim, hidden_unitD):\n",
    "        super().__init__()\n",
    "        self.rnn_cell = nn.RNNCell(embed_dim, hidden_unitD)\n",
    "        self.fc = nn.Linear(hidden_unitD, embed_dim)         ## output word's embedding vector\n",
    "    def forward(self, inputs, htD):\n",
    "        out_lst = []\n",
    "        batch_size = htD.shape[0]\n",
    "        for word in inputs:\n",
    "            htD = self.rnn_cell(word,htD)           ## htD:(batch_size,hidden_unitD)\n",
    "            out = self.fc(htD)   \n",
    "            out_lst.append(out)\n",
    "        return torch.stack(out_lst),htD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81839809-b3d4-480d-88ad-90e6c9bdd2aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN_AE_Net(\n",
       "  (emb): Embedding(1110, 300)\n",
       "  (rnnEncoder): RNN_encoder(\n",
       "    (rnn_cell): RNNCell(300, 200)\n",
       "  )\n",
       "  (fc_E2D): Linear(in_features=200, out_features=200, bias=True)\n",
       "  (rnnDecoder): RNN_decoder(\n",
       "    (rnn_cell): RNNCell(300, 200)\n",
       "    (fc): Linear(in_features=200, out_features=300, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RNN_AE_Net(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_unitE, hidden_unitD):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, embed_dim)           ## 可以先预训练一下？\n",
    "        self.rnnEncoder = RNN_encoder(embed_dim, hidden_unitE)\n",
    "        self.fc_E2D = nn.Linear(hidden_unitE, hidden_unitD)\n",
    "        self.rnnDecoder = RNN_decoder(embed_dim, hidden_unitD)\n",
    "    def forward(self,inputs):\n",
    "        emb = self.emb(inputs)\n",
    "        x = self.rnnEncoder(emb)\n",
    "        x = self.fc_E2D(x)\n",
    "        x,htD = self.rnnDecoder(emb,x)\n",
    "        return x.to(device),htD.to(device)\n",
    "\n",
    "\n",
    "embed_dim = 300\n",
    "hidden_unit = 200\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "model = RNN_AE_Net(vocab_size, embed_dim, hidden_unit, hidden_unit).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4672e91-7e43-45cc-a657-904853ce7b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "model.emb.load_state_dict(pre_param_emb,strict=False)\n",
    "model.emb.requires_grad = False\n",
    "\n",
    "mse =  nn.MSELoss()\n",
    "def loss_fn(pred,real):\n",
    "    loss = 0\n",
    "    for i in range(real.shape[0]):\n",
    "        for j in range(real.shape[1]):\n",
    "            loss += mse(pred[i,j,:],real[i,j,:])           ## loss for each word\n",
    "    return loss/(real.shape[0]*real.shape[1])\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    lossSum = 0\n",
    "    model.train()                              ### set training mode\n",
    "    for inputs in dataloader:\n",
    "        pred,htD = model(inputs)\n",
    "        real = model.emb(inputs)               ### torch.Size([seqlen, batch, embedsize])  otherwise .transpose(0, 1)\n",
    "        loss = loss_fn(pred,real)\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        print(\"=\".format(epoch+1),end='')\n",
    "    print(\"last batch loss:{}\".format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ff756e2-3492-4614-b015-220bb8cffd00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1\t=====last batch loss:1.1063904762268066\n",
      "Epoch:2\t=====last batch loss:1.1015305519104004\n",
      "Epoch:3\t=====last batch loss:1.0962250232696533\n",
      "Epoch:4\t=====last batch loss:1.0912203788757324\n",
      "Epoch:5\t=====last batch loss:1.0891518592834473\n",
      "Epoch:6\t=====last batch loss:1.086581826210022\n",
      "Epoch:7\t=====last batch loss:1.0821523666381836\n",
      "Epoch:8\t=====last batch loss:1.078304409980774\n",
      "Epoch:9\t=====last batch loss:1.0785313844680786\n",
      "Epoch:10\t=====last batch loss:1.070932388305664\n",
      "Epoch:11\t=====last batch loss:1.0637710094451904\n",
      "Epoch:12\t=====last batch loss:1.0724480152130127\n",
      "Epoch:13\t=====last batch loss:1.0683114528656006\n",
      "Epoch:14\t=====last batch loss:1.0558257102966309\n",
      "Epoch:15\t=====last batch loss:1.0469310283660889\n",
      "Epoch:16\t=====last batch loss:1.0455999374389648\n",
      "Epoch:17\t=====last batch loss:1.0410704612731934\n",
      "Epoch:18\t=====last batch loss:1.0318052768707275\n",
      "Epoch:19\t=====last batch loss:1.0438741445541382\n",
      "Epoch:20\t=====last batch loss:1.040648102760315\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    print(\"Epoch:{}\".format(epoch+1),end='\\t')\n",
    "    train(test_dl_noLable, model, loss_fn, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1e62e1-4d55-4fbf-ade3-a64da190a8c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6fbc75a-d722-4be1-9f54-bd1db7a8ff0b",
   "metadata": {},
   "source": [
    "## Retrieve from Embedding Vector\n",
    "\n",
    "?? 似乎完全没有用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72cb2221-bea5-47b4-a2db-8a6d26c80531",
   "metadata": {},
   "outputs": [],
   "source": [
    "for inputs in test_dl_noLable:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69783c06-f963-4d6c-a215-71b97b9fee1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_out,_ = model(inputs)\n",
    "pred_out = Emb2Class_model.fc(emb_out).argmax(dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "efe76139-bc07-49ec-823a-6d15888a77b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sos> i liked this movie a lot . it really intrigued me how deanna and alicia <unk> friends over such a tragedy . alicia was just a <unk> soul and deanna was so happy just to see someone after being shot . my only <unk> was that in the beginning it was kind of slow and it took <unk> to get to the <unk> of things . other than that it was great . <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str = \"\"\n",
    "for ii in inputs[:,0].cpu().numpy():\n",
    "    str += vocab.lookup_token(ii)\n",
    "    str += \" \"\n",
    "str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ddb07a54-54af-483e-af4d-dcbaf3d15744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'von ones what society equally favorite answers <eos> incredibly hidden horror knew entertainment live storyline describe interest imdb soon plays superb apart <eos> plays choice twists lars record lighting storyline live lighting fight tricks scene walter bed wave world investigating sides <eos> after main was lighting , lost tells much incredibly choice helps busy fantastic storyline incredibly camera recommended walter doll best believe recommended stop town <eos> open knew company incredibly john script <eos> sorry often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often often '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str = \"\"\n",
    "for ii in pred_out[:,0].cpu().numpy():\n",
    "    str += vocab.lookup_token(ii)\n",
    "    str += \" \"\n",
    "str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7b504d-d94a-4b28-8262-37d914af5c2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9898aebf-bbf7-41b2-a9c1-56fa83008972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "612"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e76f5056-5f84-4ba0-ba25-0fec127d3d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab['<eos>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f043df4f-4970-41ba-9d3e-55e4ae427577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<eos>'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.lookup_token(vocab['<eos>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa39865-34fd-4e09-b12a-74bd292c1f30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc13b00-dd6f-43ba-a7e6-92435fafb76e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
