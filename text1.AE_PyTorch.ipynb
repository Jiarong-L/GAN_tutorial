{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccb3a0df-0326-4774-9e20-cfb6de535528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b878782-dae7-4309-9e2a-b51e7eee4bee",
   "metadata": {},
   "source": [
    "## LoadData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39cd6ef5-ff5b-48b5-9179-285ca5235721",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext \n",
    "\n",
    "train_data = list(torchtext.datasets.IMDB(split='train',root=r'L:\\Datasets'))[12500:12600]\n",
    "tokenizer = torchtext.data.utils.get_tokenizer('basic_english')\n",
    "def yield_tokens(data):\n",
    "    for (_,text) in data:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "vocab = torchtext.vocab.build_vocab_from_iterator(yield_tokens(train_data),specials=['<unk>','<sos>','<eos>'],min_freq=3) ## '<pad>',\n",
    "vocab.set_default_index(vocab['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28eaeeb4-2d40-4ce2-aa61-bb2ee60ecb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch_noLable(data_batch):\n",
    "    text_lst = []\n",
    "    for _, _text in data_batch:\n",
    "        tk_text = vocab(['<sos>'] + tokenizer(_text) + ['<eos>'])\n",
    "        text_lst.append(torch.tensor(tk_text,dtype=torch.int64))\n",
    "    text_lst = torch.nn.utils.rnn.pad_sequence(text_lst, padding_value=float(vocab['<eos>']) )  ## pad 0 to equal length\n",
    "    return text_lst.to(device)\n",
    "\n",
    "test_dl_noLable = torch.utils.data.DataLoader(train_data, batch_size=20, shuffle=True, collate_fn = collate_batch_noLable) \n",
    "## [seq_len, batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4551ea43-be67-49fa-94f6-482a799851c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc30767f-7aa2-424e-a407-932fb9cc9370",
   "metadata": {},
   "source": [
    "## Pre-train Embedder\n",
    "主要是为了后续 Retrieve from Embedding Vector；此处只是个玩具，建议使用pre-train的word2vec等模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ccfaade-7300-4155-b92e-2dd0840507d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Emb2Class(\n",
       "  (emb): Embedding(1110, 300)\n",
       "  (fc): Linear(in_features=300, out_features=1110, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Emb2Class(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.fc = nn.Linear(embed_dim, vocab_size)\n",
    "    def forward(self,inputs):\n",
    "        emb = self.emb(inputs)\n",
    "        return self.fc(emb)#.argmax(dim=2)\n",
    "\n",
    "embed_dim = 300\n",
    "vocab_size = len(vocab)\n",
    "Emb2Class_model = Emb2Class(vocab_size, embed_dim)\n",
    "Emb2Class_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ec1eb8a-44be-4b36-9c5b-ace7631e8449",
   "metadata": {},
   "outputs": [],
   "source": [
    "ce = nn.CrossEntropyLoss()\n",
    "def Emb2Class_lossfn(pred,real):\n",
    "    loss = 0\n",
    "    for i in range(real.shape[0]):\n",
    "        loss += ce(pred[i],real[i])\n",
    "    return loss/real.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ed51f6b-d69c-44e8-ae61-a6d004818c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Emb2Class_optimizer = torch.optim.SGD(Emb2Class_model.parameters(), lr=1e-3)\n",
    "\n",
    "def Emb2Class_train(dataloader, model, loss_fn, optimizer):\n",
    "    lossSum = 0\n",
    "    model.train()                              ### set training mode\n",
    "    for inputs in dataloader:\n",
    "        pred = model(inputs)\n",
    "        loss = loss_fn(pred,inputs)\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        print(\"=\".format(epoch+1),end='')\n",
    "    print(\"last batch loss:{}\".format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b27fec7a-0a60-4582-95bf-548b3fff66b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1\t=====last batch loss:6.354733943939209\n",
      "Epoch:2\t=====last batch loss:5.915564060211182\n",
      "Epoch:3\t=====last batch loss:5.263095855712891\n",
      "Epoch:4\t=====last batch loss:4.849503040313721\n",
      "Epoch:5\t=====last batch loss:4.178357124328613\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    print(\"Epoch:{}\".format(epoch+1),end='\\t')\n",
    "    Emb2Class_train(test_dl_noLable, Emb2Class_model, Emb2Class_lossfn, Emb2Class_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "916d1218-fe49-4930-8b3b-a94bf9e6f87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_param_emb = Emb2Class_model.emb.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbf63fc-ede1-4fcd-bdfc-8cd677729902",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "057c2837-4715-4884-96a7-ce497a6c45d7",
   "metadata": {},
   "source": [
    "## RNN Encoder-Decoder\n",
    "\n",
    "```\n",
    "Encoder:\n",
    "ht_0 --> RNN_Cell --> ht_1 --> RNN_Cell --> ht_2 --> RNN_Cell --> .... --> RNN_Cell --> ht_end\n",
    "             ^                    ^                      ^                    ^\n",
    "         word1_batch             word2                  word3                word_end\n",
    "\n",
    "\n",
    "Decoder:\n",
    "ht_0 --> RNN_Cell --> ht_1 --> RNN_Cell --> ht_2 --> RNN_Cell --> .... --> RNN_Cell --> ht_stop <eos>\n",
    "          ^            |       ^              |       ^\n",
    "<SOS>   __|            o_1   __|              o_2   __|       也可以每步将 ht_0 + o_t or [o_1,...o_t] 作为输入\n",
    "\n",
    "\n",
    "GRU/Transformer 同理类似\n",
    "```\n",
    "\n",
    "### 参考\n",
    "https://zhuanlan.zhihu.com/p/80866196\n",
    "\n",
    "LSTM: https://curow.github.io/blog/LSTM-Encoder-Decoder/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "225f3236-7cc3-4c64-b794-3231010ede8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tt = nn.RNNCell(8,6)\n",
    "# tt( torch.zeros((1,8)) ,torch.zeros((1,6)) ).shape   ##==>torch.Size([1, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7d74ee0-a984-4f26-a0a2-98ea3245c49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_encoder(nn.Module):\n",
    "    def __init__(self, embed_dim, hidden_unitE):\n",
    "        super().__init__()\n",
    "        self.rnn_cell = nn.RNNCell(embed_dim,hidden_unitE)\n",
    "        self.hidden_unitE = hidden_unitE\n",
    "    def forward(self,inputs):\n",
    "        htE = torch.zeros((inputs.shape[1],self.hidden_unitE))  ## (batch_size,hidden_unitE)\n",
    "        for word in inputs:\n",
    "            # if len(torch.nonzero(word-vocab['eos']))== 0:      ## when all words == vocab['eos']\n",
    "            #     break\n",
    "            htE = self.rnn_cell(word,htE)\n",
    "        return htE\n",
    "\n",
    "class RNN_decoder(nn.Module):\n",
    "    def __init__(self, embed_dim, hidden_unitD):\n",
    "        super().__init__()\n",
    "        self.rnn_cell = nn.RNNCell(embed_dim, hidden_unitD)\n",
    "        self.fc = nn.Linear(hidden_unitD, embed_dim)         ## output word's embedding vector\n",
    "    def forward(self, inputs, htD):\n",
    "        out_lst = []\n",
    "        batch_size = htD.shape[0]\n",
    "        for word in inputs:\n",
    "            htD = self.rnn_cell(word,htD)           ## htD:(batch_size,hidden_unitD)\n",
    "            out = self.fc(htD)   \n",
    "            out_lst.append(out)\n",
    "        return torch.stack(out_lst),htD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81839809-b3d4-480d-88ad-90e6c9bdd2aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN_AE_Net(\n",
       "  (emb): Embedding(1110, 300)\n",
       "  (rnnEncoder): RNN_encoder(\n",
       "    (rnn_cell): RNNCell(300, 200)\n",
       "  )\n",
       "  (fc_E2D): Linear(in_features=200, out_features=200, bias=True)\n",
       "  (rnnDecoder): RNN_decoder(\n",
       "    (rnn_cell): RNNCell(300, 200)\n",
       "    (fc): Linear(in_features=200, out_features=300, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RNN_AE_Net(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_unitE, hidden_unitD):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, embed_dim)           ## 可以先预训练一下？\n",
    "        self.rnnEncoder = RNN_encoder(embed_dim, hidden_unitE)\n",
    "        self.fc_E2D = nn.Linear(hidden_unitE, hidden_unitD)\n",
    "        self.rnnDecoder = RNN_decoder(embed_dim, hidden_unitD)\n",
    "    def forward(self,inputs):\n",
    "        emb = self.emb(inputs)\n",
    "        x = self.rnnEncoder(emb)\n",
    "        x = self.fc_E2D(x)\n",
    "        x,htD = self.rnnDecoder(emb,x)\n",
    "        return x,htD\n",
    "\n",
    "\n",
    "embed_dim = 300\n",
    "hidden_unit = 200\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "model = RNN_AE_Net(vocab_size, embed_dim, hidden_unit, hidden_unit)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4672e91-7e43-45cc-a657-904853ce7b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "model.emb.load_state_dict(pre_param_emb,strict=False)\n",
    "model.emb.requires_grad = False\n",
    "\n",
    "mse =  nn.MSELoss()\n",
    "def loss_fn(pred,real):\n",
    "    loss = 0\n",
    "    for i in range(real.shape[0]):\n",
    "        for j in range(real.shape[1]):\n",
    "            loss += mse(pred[i,j,:],real[i,j,:])           ## loss for each word\n",
    "    return loss/(real.shape[0]*real.shape[1])\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    lossSum = 0\n",
    "    model.train()                              ### set training mode\n",
    "    for inputs in dataloader:\n",
    "        pred,htD = model(inputs)\n",
    "        real = model.emb(inputs)               ### torch.Size([seqlen, batch, embedsize])  otherwise .transpose(0, 1)\n",
    "        loss = loss_fn(pred,real)\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        print(\"=\".format(epoch+1),end='')\n",
    "    print(\"last batch loss:{}\".format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ff756e2-3492-4614-b015-220bb8cffd00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1\t=====last batch loss:1.1256271600723267\n",
      "Epoch:2\t=====last batch loss:1.1218613386154175\n",
      "Epoch:3\t=====last batch loss:1.116965413093567\n",
      "Epoch:4\t=====last batch loss:1.113127589225769\n",
      "Epoch:5\t=====last batch loss:1.1077748537063599\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    print(\"Epoch:{}\".format(epoch+1),end='\\t')\n",
    "    train(test_dl_noLable, model, loss_fn, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1e62e1-4d55-4fbf-ade3-a64da190a8c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6fbc75a-d722-4be1-9f54-bd1db7a8ff0b",
   "metadata": {},
   "source": [
    "## Retrieve from Embedding Vector\n",
    "\n",
    "?? 似乎完全没有用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72cb2221-bea5-47b4-a2db-8a6d26c80531",
   "metadata": {},
   "outputs": [],
   "source": [
    "for inputs in test_dl_noLable:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69783c06-f963-4d6c-a215-71b97b9fee1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_out,_ = model(inputs)\n",
    "pred_out = Emb2Class_model.fc(emb_out).argmax(dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efe76139-bc07-49ec-823a-6d15888a77b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sos> busy phillips put in one <unk> of a performance , both comedic and dramatic . erika christensen was good but busy <unk> the show . it was a nice <unk> after the <unk> , a movie starring busy , which <unk> all that great . if busy <unk> get a <unk> of any kind for this film it would be a <unk> . forget <unk> <unk> <unk> , see home room . <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> '"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str = \"\"\n",
    "for ii in inputs[:,0].numpy():\n",
    "    str += vocab.lookup_token(ii)\n",
    "    str += \" \"\n",
    "str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddb07a54-54af-483e-af4d-dcbaf3d15744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'adult winkelman scene as mention philipps queen happening tragedy want ever looked on graduate heard <eos> little anyone happen grandfather big winkelman victor still mental each video no dead amazing my wake still couple colour off those deep trier ever guys unique golden eyes kills uncanny channels winkelman unique matter deep girls happening unique must setting up less computer busy boring tragedy girls whatever read tragedy unique unique colour worthy grade their camera subtle subtle subtle kind subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle subtle '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str = \"\"\n",
    "for ii in pred_out[:,0].numpy():\n",
    "    str += vocab.lookup_token(ii)\n",
    "    str += \" \"\n",
    "str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7b504d-d94a-4b28-8262-37d914af5c2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9898aebf-bbf7-41b2-a9c1-56fa83008972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "796"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e76f5056-5f84-4ba0-ba25-0fec127d3d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab['<eos>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f043df4f-4970-41ba-9d3e-55e4ae427577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<eos>'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.lookup_token(vocab['<eos>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa39865-34fd-4e09-b12a-74bd292c1f30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc13b00-dd6f-43ba-a7e6-92435fafb76e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
