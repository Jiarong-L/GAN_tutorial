{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e17e5ba-7df8-4816-81b4-807929c3283e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc70601b-a588-4ea5-99e9-a0547a7bb136",
   "metadata": {},
   "source": [
    "## Transformer\n",
    "\n",
    "$attention = softmax(\\frac{QK'}{\\sqrt{K_{embDim}}})V$\n",
    "\n",
    "$Multi Head Attention = weightedSum(Attention1,Attention2,Attention3,...)$\n",
    "\n",
    "\n",
    "**Transformer** Figure1:  https://arxiv.org/abs/1706.03762 \n",
    "\n",
    "**Positional Encoding**: pos in sequence, i in input_Matrix   \n",
    "PE(pos,2i) = $sin(pos/10000^{2i/dModel})$   \n",
    "PE(pos,2i+1) = $cos(pos/10000^{2i/dModel})$  \n",
    "PE(others) = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27105c5d-daa5-4785-a033-ab0dbd26e75c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.65634158, 1.31566082, 0.95630618, 1.75965563, 1.1219455 ],\n",
       "       [1.86989336, 1.51839446, 1.07635865, 1.98092762, 1.25718701],\n",
       "       [1.64587798, 1.30523243, 0.94946118, 1.74968342, 1.11651921]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding=5\n",
    "\n",
    "WQ = np.random.rand(4,embedding)\n",
    "WK = np.random.rand(4,embedding)  ## dk\n",
    "WV = np.random.rand(4,embedding)\n",
    "M = np.random.rand(3,4)           ## query * dModel\n",
    "\n",
    "Q = M @ WQ    ## (query=3, embedding=5)\n",
    "K = M @ WK    ## (key=3, embedding=5)\n",
    "V = M @ WV    ## (value=3, embedding=5)\n",
    "\n",
    "\n",
    "def softmax(M):\n",
    "    M = M - np.max(M, axis=1, keepdims=True)\n",
    "    return np.exp(M)/np.sum(np.exp(M),axis=1,keepdims=True)\n",
    "\n",
    "\n",
    "Att = softmax(Q @ K.T /np.sqrt(embedding)) @ V\n",
    "## Multi-head = np.concatenate(Att_1,Att_2,Att_3)WH    ##-->WH is each attention's weight\n",
    "\n",
    "Att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd2037c7-9d28-420a-b9a2-b4f6e6da456c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.6563, 1.3157, 0.9563, 1.7597, 1.1219],\n",
       "        [1.8699, 1.5184, 1.0764, 1.9809, 1.2572],\n",
       "        [1.6459, 1.3052, 0.9495, 1.7497, 1.1165]], dtype=torch.float64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## pytorch Function\n",
    "\n",
    "torch.nn.functional.scaled_dot_product_attention(torch.tensor(Q), torch.tensor(K), torch.tensor(V))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ae0cfa-9542-4d15-97b5-f6524e99aa1d",
   "metadata": {},
   "source": [
    "### How to use\n",
    "\n",
    "1. layer = [nn.TransformerEncoderLayer](https://pytorch.org/docs/stable/generated/torch.nn.TransformerEncoderLayer.html)\n",
    "2. output = nn.TransformerEncoder(layer,num_layers)\n",
    "3. Attention(output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
