{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69d17e74-ab81-413c-b123-7290812112ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7cfc77-df34-49b5-992d-035aadedc44b",
   "metadata": {},
   "source": [
    "## 文本处理\n",
    "\n",
    "1. 分词/Tokenization\n",
    "```py\n",
    "list(str)     ## 1. by letter\n",
    "str.split()   ## 2. by word\n",
    "...........   ## 3. NLTK-ngrams: 有点类似k-mer，将n个相邻词合并为一个词段，稍后embed这个词段\n",
    "```\n",
    "2. 创建词表 vocab\n",
    "\n",
    "3. 词表向量化：tf-idf/one-hot/散列编码/embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "172d0bd5-5eaf-4ef1-a071-75e2427102f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "str = \"Sing in me, Muse, and through me tell the story of that man skilled in all ways of contending, the wanderer, harried for years on end, after he plundered the stronghold on the proud height of Troy\"\n",
    "\n",
    "for c in string.punctuation:\n",
    "    str = str.replace(c,' ').replace('  ',' ').lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a3a0218-03e8-483b-9c88-0e4d793ec3f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 21, 14, 10, 5, 23, 14, 27, 19, 1, 2, 26, 16, 13, 21, 22, 9, 2, 24, 19, 15, 7, 11, 17, 12, 18, 28, 20, 0, 19, 8, 12, 19, 3, 25, 2, 6]\n"
     ]
    }
   ],
   "source": [
    "vocab = dict([(v,k) for k,v in enumerate(set(str.split()))])\n",
    "s = [vocab.get(v) for v in str.split()]  \n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "721fc396-3533-4c38-9522-8298eb1c5ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 1. one-hot Mtx, each line for a word\n",
    "b = np.zeros((len(s),len(vocab))) \n",
    "for index,v in enumerate(s):\n",
    "    b[index,v] = 1\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70b0a4f5-17b3-4308-b4e0-bb2104499fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([37, 20])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 2. Embedding, each line for a word\n",
    "emb_layer = torch.nn.Embedding(len(vocab),20)\n",
    "emb = emb_layer(torch.LongTensor(s))\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852f687e-6959-44e4-a473-8a622957a25d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "afdec691-88ee-483c-8e73-aa714d645c88",
   "metadata": {},
   "source": [
    "## TorchText\n",
    "\n",
    "```\n",
    "torchtext.datasets.* 提供常见数据集  但是与torch==2.3.0不相容；且容易出错，建议转换为list()\n",
    "\n",
    "\n",
    "```\n",
    "* 各种文本处理工具: https://pytorch.org/text/stable/data_utils.html   \n",
    "* 忘记 vocab.set_default_index 后续调用如果遇到不在vocab中的词后程序会崩溃"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5799132e-d9b7-4f88-ae61-20462a224e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.16.2+cpu'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchtext     ## pip install torchtext; pip install torchdata\n",
    "torchtext.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db3ff0c2-03e8-4ac5-ae00-a090e7b4a873",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = list(torchtext.datasets.IMDB(split='train'))\n",
    "tokenizer = torchtext.data.utils.get_tokenizer('basic_english')\n",
    "def yield_tokens(data):\n",
    "    for (_,text) in data:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "vocab = torchtext.vocab.build_vocab_from_iterator(yield_tokens(test_data),specials=['<pad>','<unk>'],min_freq=3)\n",
    "vocab.set_default_index(vocab['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48296c66-6337-418a-aa13-c9ce3c735903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27771"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d9cecbc-a8bc-4845-aefe-ad9a05ede43d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,\n",
       " 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "262b95c3-28e9-4944-9a27-c345937d822d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'rented',\n",
       " 'i',\n",
       " 'am',\n",
       " 'curious-yellow',\n",
       " 'from',\n",
       " 'my',\n",
       " 'video',\n",
       " 'store',\n",
       " 'because',\n",
       " 'of',\n",
       " 'all',\n",
       " 'the',\n",
       " 'controversy',\n",
       " 'that',\n",
       " 'surrounded',\n",
       " 'it',\n",
       " 'when',\n",
       " 'it',\n",
       " 'was',\n",
       " 'first',\n",
       " 'released',\n",
       " 'in',\n",
       " '1967',\n",
       " '.',\n",
       " 'i',\n",
       " 'also',\n",
       " 'heard',\n",
       " 'that',\n",
       " 'at',\n",
       " 'first',\n",
       " 'it',\n",
       " 'was',\n",
       " 'seized',\n",
       " 'by',\n",
       " 'u',\n",
       " '.',\n",
       " 's',\n",
       " '.',\n",
       " 'customs',\n",
       " 'if',\n",
       " 'it',\n",
       " 'ever',\n",
       " 'tried',\n",
       " 'to',\n",
       " 'enter',\n",
       " 'this',\n",
       " 'country',\n",
       " ',',\n",
       " 'therefore',\n",
       " 'being',\n",
       " 'a',\n",
       " 'fan',\n",
       " 'of',\n",
       " 'films',\n",
       " 'considered',\n",
       " 'controversial',\n",
       " 'i',\n",
       " 'really',\n",
       " 'had',\n",
       " 'to',\n",
       " 'see',\n",
       " 'this',\n",
       " 'for',\n",
       " 'myself',\n",
       " '.',\n",
       " 'the',\n",
       " 'plot',\n",
       " 'is',\n",
       " 'centered',\n",
       " 'around',\n",
       " 'a',\n",
       " 'young',\n",
       " 'swedish',\n",
       " 'drama',\n",
       " 'student',\n",
       " 'named',\n",
       " 'lena',\n",
       " 'who',\n",
       " 'wants',\n",
       " 'to',\n",
       " 'learn',\n",
       " 'everything',\n",
       " 'she',\n",
       " 'can',\n",
       " 'about',\n",
       " 'life',\n",
       " '.',\n",
       " 'in',\n",
       " 'particular',\n",
       " 'she',\n",
       " 'wants',\n",
       " 'to',\n",
       " 'focus',\n",
       " 'her',\n",
       " 'attentions',\n",
       " 'to',\n",
       " 'making',\n",
       " 'some',\n",
       " 'sort',\n",
       " 'of',\n",
       " 'documentary',\n",
       " 'on',\n",
       " 'what',\n",
       " 'the',\n",
       " 'average',\n",
       " 'swede',\n",
       " 'thought',\n",
       " 'about',\n",
       " 'certain',\n",
       " 'political',\n",
       " 'issues',\n",
       " 'such',\n",
       " 'as',\n",
       " 'the',\n",
       " 'vietnam',\n",
       " 'war',\n",
       " 'and',\n",
       " 'race',\n",
       " 'issues',\n",
       " 'in',\n",
       " 'the',\n",
       " 'united',\n",
       " 'states',\n",
       " '.',\n",
       " 'in',\n",
       " 'between',\n",
       " 'asking',\n",
       " 'politicians',\n",
       " 'and',\n",
       " 'ordinary',\n",
       " 'denizens',\n",
       " 'of',\n",
       " 'stockholm',\n",
       " 'about',\n",
       " 'their',\n",
       " 'opinions',\n",
       " 'on',\n",
       " 'politics',\n",
       " ',',\n",
       " 'she',\n",
       " 'has',\n",
       " 'sex',\n",
       " 'with',\n",
       " 'her',\n",
       " 'drama',\n",
       " 'teacher',\n",
       " ',',\n",
       " 'classmates',\n",
       " ',',\n",
       " 'and',\n",
       " 'married',\n",
       " 'men',\n",
       " '.',\n",
       " 'what',\n",
       " 'kills',\n",
       " 'me',\n",
       " 'about',\n",
       " 'i',\n",
       " 'am',\n",
       " 'curious-yellow',\n",
       " 'is',\n",
       " 'that',\n",
       " '40',\n",
       " 'years',\n",
       " 'ago',\n",
       " ',',\n",
       " 'this',\n",
       " 'was',\n",
       " 'considered',\n",
       " 'pornographic',\n",
       " '.',\n",
       " 'really',\n",
       " ',',\n",
       " 'the',\n",
       " 'sex',\n",
       " 'and',\n",
       " 'nudity',\n",
       " 'scenes',\n",
       " 'are',\n",
       " 'few',\n",
       " 'and',\n",
       " 'far',\n",
       " 'between',\n",
       " ',',\n",
       " 'even',\n",
       " 'then',\n",
       " 'it',\n",
       " \"'\",\n",
       " 's',\n",
       " 'not',\n",
       " 'shot',\n",
       " 'like',\n",
       " 'some',\n",
       " 'cheaply',\n",
       " 'made',\n",
       " 'porno',\n",
       " '.',\n",
       " 'while',\n",
       " 'my',\n",
       " 'countrymen',\n",
       " 'mind',\n",
       " 'find',\n",
       " 'it',\n",
       " 'shocking',\n",
       " ',',\n",
       " 'in',\n",
       " 'reality',\n",
       " 'sex',\n",
       " 'and',\n",
       " 'nudity',\n",
       " 'are',\n",
       " 'a',\n",
       " 'major',\n",
       " 'staple',\n",
       " 'in',\n",
       " 'swedish',\n",
       " 'cinema',\n",
       " '.',\n",
       " 'even',\n",
       " 'ingmar',\n",
       " 'bergman',\n",
       " ',',\n",
       " 'arguably',\n",
       " 'their',\n",
       " 'answer',\n",
       " 'to',\n",
       " 'good',\n",
       " 'old',\n",
       " 'boy',\n",
       " 'john',\n",
       " 'ford',\n",
       " ',',\n",
       " 'had',\n",
       " 'sex',\n",
       " 'scenes',\n",
       " 'in',\n",
       " 'his',\n",
       " 'films',\n",
       " '.',\n",
       " 'i',\n",
       " 'do',\n",
       " 'commend',\n",
       " 'the',\n",
       " 'filmmakers',\n",
       " 'for',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'that',\n",
       " 'any',\n",
       " 'sex',\n",
       " 'shown',\n",
       " 'in',\n",
       " 'the',\n",
       " 'film',\n",
       " 'is',\n",
       " 'shown',\n",
       " 'for',\n",
       " 'artistic',\n",
       " 'purposes',\n",
       " 'rather',\n",
       " 'than',\n",
       " 'just',\n",
       " 'to',\n",
       " 'shock',\n",
       " 'people',\n",
       " 'and',\n",
       " 'make',\n",
       " 'money',\n",
       " 'to',\n",
       " 'be',\n",
       " 'shown',\n",
       " 'in',\n",
       " 'pornographic',\n",
       " 'theaters',\n",
       " 'in',\n",
       " 'america',\n",
       " '.',\n",
       " 'i',\n",
       " 'am',\n",
       " 'curious-yellow',\n",
       " 'is',\n",
       " 'a',\n",
       " 'good',\n",
       " 'film',\n",
       " 'for',\n",
       " 'anyone',\n",
       " 'wanting',\n",
       " 'to',\n",
       " 'study',\n",
       " 'the',\n",
       " 'meat',\n",
       " 'and',\n",
       " 'potatoes',\n",
       " '(',\n",
       " 'no',\n",
       " 'pun',\n",
       " 'intended',\n",
       " ')',\n",
       " 'of',\n",
       " 'swedish',\n",
       " 'cinema',\n",
       " '.',\n",
       " 'but',\n",
       " 'really',\n",
       " ',',\n",
       " 'this',\n",
       " 'film',\n",
       " 'doesn',\n",
       " \"'\",\n",
       " 't',\n",
       " 'have',\n",
       " 'much',\n",
       " 'of',\n",
       " 'a',\n",
       " 'plot',\n",
       " '.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(yield_tokens(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a25fc95b-55e8-4630-981e-7437b66b38b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "229"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab['am']   ## index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67db4fe6-c07b-4134-a703-01cf323598a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12, 173]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(['i','love'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fdd0c44-8058-4cee-a31f-1cd5fc4cabff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12,\n",
       " 1152,\n",
       " 12,\n",
       " 229,\n",
       " 24140,\n",
       " 49,\n",
       " 71,\n",
       " 350,\n",
       " 1023,\n",
       " 86,\n",
       " 8,\n",
       " 39,\n",
       " 3,\n",
       " 7332,\n",
       " 15,\n",
       " 2974,\n",
       " 11,\n",
       " 65,\n",
       " 11,\n",
       " 17,\n",
       " 97,\n",
       " 747,\n",
       " 13,\n",
       " 7813,\n",
       " 2,\n",
       " 12,\n",
       " 110,\n",
       " 563,\n",
       " 15,\n",
       " 37,\n",
       " 97,\n",
       " 11,\n",
       " 17,\n",
       " 17607,\n",
       " 45,\n",
       " 1465,\n",
       " 2,\n",
       " 16,\n",
       " 2,\n",
       " 11062,\n",
       " 50,\n",
       " 11,\n",
       " 123,\n",
       " 607,\n",
       " 9,\n",
       " 2635,\n",
       " 14,\n",
       " 799,\n",
       " 4,\n",
       " 1486,\n",
       " 117,\n",
       " 5,\n",
       " 371,\n",
       " 8,\n",
       " 128,\n",
       " 1205,\n",
       " 3534,\n",
       " 12,\n",
       " 68,\n",
       " 69,\n",
       " 9,\n",
       " 76,\n",
       " 14,\n",
       " 19,\n",
       " 478,\n",
       " 2,\n",
       " 3,\n",
       " 100,\n",
       " 10,\n",
       " 5504,\n",
       " 190,\n",
       " 5,\n",
       " 265,\n",
       " 3993,\n",
       " 614,\n",
       " 1271,\n",
       " 830,\n",
       " 6787,\n",
       " 48,\n",
       " 517,\n",
       " 9,\n",
       " 900,\n",
       " 286,\n",
       " 67,\n",
       " 58,\n",
       " 51,\n",
       " 160,\n",
       " 2,\n",
       " 13,\n",
       " 978,\n",
       " 67,\n",
       " 517,\n",
       " 9,\n",
       " 1215,\n",
       " 56,\n",
       " 12245,\n",
       " 9,\n",
       " 232,\n",
       " 54,\n",
       " 397,\n",
       " 8,\n",
       " 813,\n",
       " 27,\n",
       " 53,\n",
       " 3,\n",
       " 752,\n",
       " 22749,\n",
       " 206,\n",
       " 51,\n",
       " 906,\n",
       " 1170,\n",
       " 1461,\n",
       " 151,\n",
       " 22,\n",
       " 3,\n",
       " 2429,\n",
       " 457,\n",
       " 6,\n",
       " 1609,\n",
       " 1461,\n",
       " 13,\n",
       " 3,\n",
       " 2670,\n",
       " 1767,\n",
       " 2,\n",
       " 13,\n",
       " 258,\n",
       " 1742,\n",
       " 7456,\n",
       " 6,\n",
       " 2317,\n",
       " 1,\n",
       " 8,\n",
       " 16110,\n",
       " 51,\n",
       " 79,\n",
       " 4553,\n",
       " 27,\n",
       " 2406,\n",
       " 4,\n",
       " 67,\n",
       " 59,\n",
       " 337,\n",
       " 21,\n",
       " 56,\n",
       " 614,\n",
       " 1549,\n",
       " 4,\n",
       " 9545,\n",
       " 4,\n",
       " 6,\n",
       " 1187,\n",
       " 418,\n",
       " 2,\n",
       " 53,\n",
       " 890,\n",
       " 75,\n",
       " 51,\n",
       " 12,\n",
       " 229,\n",
       " 24140,\n",
       " 10,\n",
       " 15,\n",
       " 1595,\n",
       " 207,\n",
       " 702,\n",
       " 4,\n",
       " 14,\n",
       " 17,\n",
       " 1205,\n",
       " 7457,\n",
       " 2,\n",
       " 68,\n",
       " 4,\n",
       " 3,\n",
       " 337,\n",
       " 6,\n",
       " 718,\n",
       " 143,\n",
       " 31,\n",
       " 168,\n",
       " 6,\n",
       " 222,\n",
       " 258,\n",
       " 4,\n",
       " 57,\n",
       " 89,\n",
       " 11,\n",
       " 7,\n",
       " 16,\n",
       " 29,\n",
       " 307,\n",
       " 42,\n",
       " 54,\n",
       " 4964,\n",
       " 95,\n",
       " 2754,\n",
       " 2,\n",
       " 154,\n",
       " 71,\n",
       " 24084,\n",
       " 368,\n",
       " 195,\n",
       " 11,\n",
       " 1581,\n",
       " 4,\n",
       " 13,\n",
       " 787,\n",
       " 337,\n",
       " 6,\n",
       " 718,\n",
       " 31,\n",
       " 5,\n",
       " 637,\n",
       " 9031,\n",
       " 13,\n",
       " 3993,\n",
       " 533,\n",
       " 2,\n",
       " 57,\n",
       " 12566,\n",
       " 3388,\n",
       " 4,\n",
       " 5374,\n",
       " 79,\n",
       " 1310,\n",
       " 9,\n",
       " 60,\n",
       " 185,\n",
       " 493,\n",
       " 385,\n",
       " 1977,\n",
       " 4,\n",
       " 69,\n",
       " 337,\n",
       " 143,\n",
       " 13,\n",
       " 38,\n",
       " 128,\n",
       " 2,\n",
       " 12,\n",
       " 80,\n",
       " 11637,\n",
       " 3,\n",
       " 838,\n",
       " 19,\n",
       " 3,\n",
       " 197,\n",
       " 15,\n",
       " 92,\n",
       " 337,\n",
       " 692,\n",
       " 13,\n",
       " 3,\n",
       " 24,\n",
       " 10,\n",
       " 692,\n",
       " 19,\n",
       " 1667,\n",
       " 4918,\n",
       " 252,\n",
       " 81,\n",
       " 44,\n",
       " 9,\n",
       " 1351,\n",
       " 88,\n",
       " 6,\n",
       " 93,\n",
       " 214,\n",
       " 9,\n",
       " 32,\n",
       " 692,\n",
       " 13,\n",
       " 7457,\n",
       " 2012,\n",
       " 13,\n",
       " 948,\n",
       " 2,\n",
       " 12,\n",
       " 229,\n",
       " 24140,\n",
       " 10,\n",
       " 5,\n",
       " 60,\n",
       " 24,\n",
       " 19,\n",
       " 247,\n",
       " 1797,\n",
       " 9,\n",
       " 2306,\n",
       " 3,\n",
       " 2875,\n",
       " 6,\n",
       " 14660,\n",
       " 28,\n",
       " 55,\n",
       " 4418,\n",
       " 1217,\n",
       " 26,\n",
       " 8,\n",
       " 3993,\n",
       " 533,\n",
       " 2,\n",
       " 20,\n",
       " 68,\n",
       " 4,\n",
       " 14,\n",
       " 24,\n",
       " 149,\n",
       " 7,\n",
       " 23,\n",
       " 30,\n",
       " 84,\n",
       " 8,\n",
       " 5,\n",
       " 100,\n",
       " 2]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(next(yield_tokens(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca1a4ed-6fe5-4998-802d-1224c20dfc0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64633182-4d0c-484b-bab5-30149cd543fe",
   "metadata": {},
   "source": [
    "## DataLoader\n",
    "\n",
    "设定 collate_fn batch ...\n",
    "\n",
    "此例是为了torch.nn.EmbeddingBag的输入做准备\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bd52589-9700-42b3-a816-0fdf9cf25db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(data_batch):\n",
    "    label_lst, text_lst, offset_lst = [],[],[]\n",
    "    for _label, _text in data_batch:\n",
    "        label_lst.append(_label)\n",
    "        tk_text = vocab(tokenizer(_text))\n",
    "        text_lst.append(torch.tensor(tk_text,dtype=torch.int64))\n",
    "        offset_lst.append(len(tk_text))\n",
    "    label_lst = torch.tensor(label_lst)\n",
    "    text_lst = torch.cat(text_lst)\n",
    "    offsets = torch.cat((torch.tensor([0]), torch.tensor(offset_lst[:-1]).cumsum(dim=0) ))\n",
    "    return label_lst.to(device),text_lst.to(device),offsets.to(device)\n",
    "\n",
    "\n",
    "test_dl = torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=True, collate_fn = collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "489fbf14-df06-4356-9584-675e24da9a9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " tensor([ 12, 206,  15,  ..., 689,  25,   2]),\n",
       " tensor([   0,  312,  547, 1260, 1444, 1597, 1822, 2291, 2503, 2674, 2812, 2943,\n",
       "         3166, 3455, 4337, 4728, 4938, 6046, 6227, 6447]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for tt in test_dl:\n",
    "    pass\n",
    "\n",
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3eccba-8344-4fab-a67b-08b4385e87da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4afa135-1fb0-44d7-b7c2-371dd06e774a",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "```\n",
    "## torch.nn.EmbeddingBag 接受词表进行 Embedding，并对 Embedding 输出进行聚合：求和/均值/最大值/。。。\n",
    "## 可以将一个批次中全部文本合并为一个长序列，并记录其中每一条文本的 **偏移值**（其所在位置）\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "568a6427-af9d-4ab4-ab77-20c9a8fe03ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextClassifyModel(\n",
       "  (Embed_Bag): EmbeddingBag(27771, 100, mode='mean')\n",
       "  (fc): Linear(in_features=100, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TextClassifyModel(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim):\n",
    "        super().__init__()\n",
    "        self.Embed_Bag = torch.nn.EmbeddingBag(vocab_size,embed_dim)\n",
    "        self.fc = torch.nn.Linear(embed_dim, 2)\n",
    "    def forward(self, text, offset):\n",
    "        embd = self.Embed_Bag(text,offset)\n",
    "        return self.fc(embd)\n",
    "\n",
    "model = TextClassifyModel(len(vocab),100)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2090d471-36c5-43a8-949d-ef168f2f324b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-1)\n",
    "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7de58ab8-05f4-470e-8ccf-d0c37b1ee88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    lossSum = 0\n",
    "    model.train()                                    ### set training mode\n",
    "    for label_lst,text_lst,offsets in dataloader:\n",
    "        # Compute prediction error\n",
    "        pred = model(text_lst,offsets)\n",
    "        loss = loss_fn(pred, label_lst)\n",
    "        lossSum += loss.item()\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    avgTrainingLoss = lossSum/len(dataloader)\n",
    "    return avgTrainingLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b59ccb3a-e3ae-43ba-82d1-6b304f35ccf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1----Train Loss:: 0.059540\n",
      "Epoch 2----Train Loss:: 0.008917\n",
      "Epoch 3----Train Loss:: 0.005182\n",
      "Epoch 4----Train Loss:: 0.003663\n",
      "Epoch 5----Train Loss:: 0.002834\n",
      "Epoch 6----Train Loss:: 0.002312\n",
      "Epoch 7----Train Loss:: 0.001951\n",
      "Epoch 8----Train Loss:: 0.001689\n",
      "Epoch 9----Train Loss:: 0.001488\n",
      "Epoch 10----Train Loss:: 0.001331\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    avgTrainingLoss = train(test_dl, model, loss_fn, optimizer)\n",
    "    print(f'Epoch {t+1}----Train Loss:: {avgTrainingLoss:>7f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d99bed-55c7-4610-ba54-7dea868237d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
